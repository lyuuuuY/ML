---
title: "Assignment 3"
author: "Cui Qingxuan"
date: "`r Sys.Date()`"
output: pdf_document
---

# Assignment 3

## 3.1.1 Make a scatterplot showing a Plasma glucose concentration on Age where observations are colored by Diabetes levels. 
![Plasma glucose concentration vs Age]["LAB1figure/3.1"]

## 3.1.2 Do you think that Diabetes is easy to classify by a standard logistic regression model that uses these two variables as features? Motivate your answer.
From the scatter plot between the given 2 features, that there is no any apparent boundary to classify the green points and red points representing whether being healthy or having diabetes. Based on that, I think it is not easy.

## 3.2

### 3.2.1 Report the probabilistic equation of the estimated model (i.e., how the target depends on the features and the estimated model parameters probabilistically).
probabilistic equation:  y bar =  0.0355825 x1 +  0.02450157 x2 +  -5.897858

### 3.2.2  Comment on the quality of the classification by using these results. 
Based on accuracy of the prediction, besides the comparison between plots, it is obviou that the quality is not good enough to classify them well.

## 3.3  Comment whether the decision boundary seems to catch the data distribution well.
The decision boundary is represented by a linear function, while the data distribution is more complicated than the data which can be caught by linear function.

## 3.4  By using these plots, comment on what happens with the prediction when r value changes.
With the increasing value of r, less sample would be predicted as positive.

## 3.5  

## 3.5.1 What can you say about the quality of this model compared to the previous logistic regression model? 
After adding the non-linear elements into feature, the performance improved a little, but either cannot classify well.

### 3.5.2 How have the basis expansion trick affected the shape of the decision boundary and the prediction accuracy? 
The decision boundary generated from original features is a linear function, while the present decision boundary in the shape of exponential function plot.

## Appendix for Assignment 3

```{r load csv}
data = read.csv("pima-indians-diabetes.csv")
colnames(data) = list("pegnant_times", "glucose_level", "blood_pressure", "skin_thickness", "serum_insulin", "boby_mass", "diabetes_pedigree_func", "age", "diabetes")
```
3.1
```{r plot for 2 features}
library(ggplot2)

ggplot(data, aes(age, glucose_level, color = as.factor(diabetes))) + 
      geom_point(size = 2) +
      labs(title = "Scatter Plot between Age and Glucose Level",
            x = "Age", 
            y = "Glucose Level") + 
       scale_color_manual(values = c("0" = "green", "1" = "red")) +
      theme_minimal()
```
3.2
```{r data processing for model}
model_data = as.data.frame(x = cbind(data$glucose_level, data$age, data$diabetes))
colnames(model_data) = list("x1", "x2", "label")
```

```{r model construction}
library(lattice)
library(caret)
model = train(as.factor(label) ~ ., 
              data = model_data, 
              method = "glm", 
              family = "binomial")
# summary(model)
```

```{r calculate loss and evaluate}
output_prob = predict(model, model_data, type = "prob")[,2]
output_label  = ifelse(output_prob >= 0.5, 1, 0)

coef = coef(model$finalModel)
intercept = coef[1]
x1 = coef[2]
x2 = coef[3]
loss  = mean((as.numeric(output_label) - as.numeric(model_data$label)) ** 2)
cat("The misclassification error is:", loss, "\n")

acc = mean(output_label == model_data$label)
cat("The accuracy can be considered as quality of classification:", acc)
```

```{r plot for showing predictted values}
ggplot(cbind(model_data,output_label), aes(x2, x1, color = as.factor(output_label))) + 
      geom_point(size = 2) +
      labs(title = "Scatter Plot between Age and Glucose Level",
            x = "Age", 
            y = "Glucose Level") + 
       scale_color_manual(values = c("0" = "green", "1" = "red")) +
      theme_minimal()
```

3.3
```{r add the decision boundary into plot}
coeff = coef(model$finalModel)
intercept = coeff[1]
param_x1 = coeff[2]
param_x2 = coeff[3]
cat("Boundary Decisionï¼š", intercept, "+", param_x1, "* x1 +", param_x2, "* x2 = 0")
```

```{r plot for showing predictted values with decision boundaries}
# create the gird
x2_range = seq(min(model_data$x2), max(model_data$x2), length.out = dim(model_data))
x1_bound = -(intercept + param_x2 * x2_range) / param_x1

ggplot(cbind(model_data,output_label), aes(x2, x1)) + 
      geom_point(aes(color = as.factor(output_label)),size = 2) +
       geom_line(aes(x = x2_range, y = x1_bound), color = "black", linetype = "dashed")+
      labs(title = "Scatter Plot between Age and Glucose Level",
            x = "Age", 
            y = "Glucose Level") + 
       scale_color_manual(values = c("0" = "green", "1" = "red")) +
      theme_minimal()
```

3.4
```{r plot for setting r = 0.2}
r = c(0.2, 0.8)
output_label  = ifelse(output_prob >= r[1], 1, 0)

ggplot(cbind(model_data,output_label), aes(x2, x1, color = as.factor(output_label))) + 
      geom_point(size = 2) +
      labs(title = "Scatter Plot between Age and Glucose Level",
            x = "Age", 
            y = "Glucose Level") + 
       scale_color_manual(values = c("0" = "green", "1" = "red")) +
      theme_minimal()
```
```{r plot for setting r=0.8}
output_label  = ifelse(output_prob >= r[2], 1, 0)
ggplot(cbind(model_data,output_label), aes(x2, x1, color = as.factor(output_label))) + 
      geom_point(size = 2) +
      labs(title = "Scatter Plot between Age and Glucose Level",
            x = "Age", 
            y = "Glucose Level") + 
       scale_color_manual(values = c("0" = "green", "1" = "red")) +
      theme_minimal()
```


3.5
```{r computing new features}
label = model_data$label
model_data$label = NULL

for (i in 0:4){
  feature_name = paste0("z", as.character(i+1))
  model_data[[feature_name]] = (model_data$x1 ** (4 - i)) * (model_data$x2 ** i)
}
model_data$label = label
head(model_data)
```

```{r train the new model using new features}
model = train(as.factor(label) ~ ., 
              data = model_data, 
              method = "glm", 
              family = "binomial")
output_prob = predict(model, model_data, type = "prob")[,2]
output_label  = ifelse(output_prob >= 0.5, 1, 0)

loss  = mean((as.numeric(output_label) - as.numeric(model_data$label)) ** 2)
acc = mean(output_label == model_data$label)
cat("The misclassification error is:", loss, "\n")
cat("The accuracy can be considered as quality of classification:", acc)
```

```{r plot for showing the decision boundaries}
db_points = model_data[abs(output_prob - 0.5) < 0.05,]

ggplot() +
  geom_point(data = cbind(model_data, output_label), aes(x = x2, y = x1, color = as.factor(output_label))) +
  labs(title = "Scatter Plot between Age and Glucose Level",
       x = "Age", 
       y = "Glucose Level") + 
  scale_color_manual(values = c("0" = "green", "1" = "red")) +
  geom_smooth(data = db_points, aes(x = x2, y = x1), method = "loess",color = "black", linetype = "dashed") +
  theme_minimal()
```

